<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Next Three Years of LLM Performance — January 18, 2026</title>

    <!-- Fonts: Editorial elegance meets technical clarity -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Fraunces:opsz,wght@9..144,400;9..144,600;9..144,700&family=Source+Sans+3:wght@400;500;600&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">

    <style>
        :root {
            /* Core palette - teal/cyan tech theme */
            --bg: #FDFBF7;
            --bg-alt: #F5F1EA;
            --text: #1A1815;
            --text-secondary: #4D5C6A;
            --accent: #0D6E8A;
            --accent-soft: rgba(13, 110, 138, 0.12);
            --accent-hover: #0A5A72;
            --border: #D8E2E8;
            --border-strong: #B8C8D4;

            /* Typography scale */
            --font-display: 'Fraunces', Georgia, serif;
            --font-body: 'Source Sans 3', -apple-system, sans-serif;
            --font-mono: 'JetBrains Mono', monospace;

            /* Spacing */
            --space-xs: 0.5rem;
            --space-sm: 1rem;
            --space-md: 1.5rem;
            --space-lg: 2.5rem;
            --space-xl: 4rem;
            --space-2xl: 6rem;

            /* Layout */
            --content-width: 680px;
            --wide-width: 900px;
        }

        /* Dark mode variant */
        @media (prefers-color-scheme: dark) {
            :root {
                --bg: #141210;
                --bg-alt: #1E1B18;
                --text: #F5F1EA;
                --text-secondary: #A69E93;
                --accent: #2DD4BF;
                --accent-soft: rgba(45, 212, 191, 0.15);
                --accent-hover: #5EEAD4;
                --border: #2E2A25;
                --border-strong: #3D3832;
            }
        }

        *, *::before, *::after {
            box-sizing: border-box;
        }

        html {
            font-size: 18px;
            scroll-behavior: smooth;
        }

        body {
            margin: 0;
            padding: 0;
            font-family: var(--font-body);
            font-weight: 400;
            line-height: 1.7;
            color: var(--text);
            background: var(--bg);
            -webkit-font-smoothing: antialiased;
            -moz-osx-font-smoothing: grayscale;
        }

        /* ========================================
           HEADER
           ======================================== */

        .header {
            padding: var(--space-lg) var(--space-md);
            border-bottom: 1px solid var(--border);
        }

        .header-inner {
            max-width: var(--content-width);
            margin: 0 auto;
            display: flex;
            justify-content: space-between;
            align-items: baseline;
        }

        .newsletter-brand {
            font-family: var(--font-display);
            font-size: 1.1rem;
            font-weight: 600;
            color: var(--text);
            text-decoration: none;
            letter-spacing: -0.01em;
        }

        .newsletter-date {
            font-family: var(--font-mono);
            font-size: 0.75rem;
            color: var(--text-secondary);
            letter-spacing: 0.03em;
        }

        /* ========================================
           HERO
           ======================================== */

        .hero {
            padding: var(--space-xl) var(--space-md) var(--space-2xl);
            text-align: center;
        }

        .hero-inner {
            max-width: var(--content-width);
            margin: 0 auto;
        }

        .hero-label {
            display: inline-block;
            font-family: var(--font-mono);
            font-size: 0.7rem;
            font-weight: 500;
            text-transform: uppercase;
            letter-spacing: 0.15em;
            color: var(--accent);
            background: var(--accent-soft);
            padding: 0.4em 1em;
            border-radius: 2px;
            margin-bottom: var(--space-md);
        }

        .hero-title {
            font-family: var(--font-display);
            font-size: clamp(2.2rem, 5vw, 3.2rem);
            font-weight: 700;
            line-height: 1.15;
            letter-spacing: -0.025em;
            margin: 0 0 var(--space-md);
            color: var(--text);
        }

        .hero-subtitle {
            font-size: 1.15rem;
            color: var(--text-secondary);
            max-width: 540px;
            margin: 0 auto;
            line-height: 1.6;
        }

        .hero-image {
            margin-top: var(--space-xl);
            border-radius: 8px;
            overflow: hidden;
            box-shadow:
                0 4px 6px rgba(0,0,0,0.04),
                0 12px 24px rgba(0,0,0,0.06);
        }

        .hero-image img {
            width: 100%;
            height: auto;
            display: block;
        }

        /* ========================================
           CONTENT SECTIONS
           ======================================== */

        .content {
            max-width: var(--content-width);
            margin: 0 auto;
            padding: 0 var(--space-md);
        }

        .section {
            padding: var(--space-xl) 0;
            border-bottom: 1px solid var(--border);
            opacity: 0;
            transform: translateY(20px);
            animation: fadeInUp 0.6s ease forwards;
        }

        .section:nth-child(1) { animation-delay: 0.1s; }
        .section:nth-child(2) { animation-delay: 0.2s; }
        .section:nth-child(3) { animation-delay: 0.3s; }
        .section:nth-child(4) { animation-delay: 0.4s; }
        .section:nth-child(5) { animation-delay: 0.5s; }
        .section:nth-child(6) { animation-delay: 0.6s; }
        .section:nth-child(7) { animation-delay: 0.7s; }

        .section:last-child {
            border-bottom: none;
        }

        @keyframes fadeInUp {
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .section-number {
            font-family: var(--font-mono);
            font-size: 0.7rem;
            font-weight: 500;
            color: var(--accent);
            letter-spacing: 0.1em;
            margin-bottom: var(--space-xs);
        }

        .section-title {
            font-family: var(--font-display);
            font-size: 1.6rem;
            font-weight: 600;
            line-height: 1.3;
            letter-spacing: -0.015em;
            margin: 0 0 var(--space-sm);
            color: var(--text);
        }

        .section-meta {
            display: flex;
            gap: var(--space-sm);
            align-items: center;
            margin-bottom: var(--space-md);
            flex-wrap: wrap;
        }

        .section-source {
            font-family: var(--font-mono);
            font-size: 0.72rem;
            color: var(--text-secondary);
            letter-spacing: 0.02em;
        }

        .section-source a {
            color: var(--accent);
            text-decoration: none;
            border-bottom: 1px solid transparent;
            transition: border-color 0.2s ease;
        }

        .section-source a:hover {
            border-color: var(--accent);
        }

        .section-date {
            font-family: var(--font-mono);
            font-size: 0.72rem;
            color: var(--text-secondary);
            letter-spacing: 0.02em;
        }

        .section-date::before {
            content: "•";
            margin: 0 0.5em;
        }

        .section-body p {
            margin: 0 0 var(--space-sm);
        }

        .section-body p:last-child {
            margin-bottom: 0;
        }

        .section-body a {
            color: var(--accent);
            text-decoration: underline;
            text-decoration-color: var(--accent-soft);
            text-underline-offset: 2px;
            transition: text-decoration-color 0.2s ease;
        }

        .section-body a:hover {
            text-decoration-color: var(--accent);
        }

        .section-image {
            margin: var(--space-md) 0;
            border-radius: 6px;
            overflow: hidden;
        }

        .section-image img {
            width: 100%;
            height: auto;
            display: block;
        }

        .article-image {
            margin: 0 0 1.5rem 0;
            border-radius: 8px;
            overflow: hidden;
        }
        .article-image img {
            width: 100%;
            height: auto;
            display: block;
        }

        /* Callout boxes */
        .callout {
            background: var(--bg-alt);
            border-left: 3px solid var(--accent);
            padding: var(--space-md);
            margin: var(--space-md) 0;
            border-radius: 0 4px 4px 0;
        }

        .callout p {
            margin: 0;
            font-size: 0.95rem;
        }

        /* Code/technical snippets */
        code {
            font-family: var(--font-mono);
            font-size: 0.85em;
            background: var(--bg-alt);
            padding: 0.15em 0.4em;
            border-radius: 3px;
            color: var(--accent);
        }

        /* Charts and data visualizations */
        .chart {
            margin: var(--space-md) 0;
            padding: 0;
        }

        .chart img {
            width: 100%;
            height: auto;
            display: block;
            border-radius: 6px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.06);
        }

        .chart figcaption {
            font-family: var(--font-mono);
            font-size: 0.75rem;
            color: var(--text-secondary);
            margin-top: var(--space-xs);
            padding: 0 var(--space-xs);
            line-height: 1.5;
        }

        /* ========================================
           CLOSING / FOOTER
           ======================================== */

        .closing {
            padding: var(--space-2xl) var(--space-md);
            text-align: center;
            background: var(--bg-alt);
        }

        .closing-inner {
            max-width: var(--content-width);
            margin: 0 auto;
        }

        .closing-title {
            font-family: var(--font-display);
            font-size: 1.4rem;
            font-weight: 600;
            margin: 0 0 var(--space-sm);
        }

        .closing-text {
            color: var(--text-secondary);
            margin: 0 0 var(--space-md);
        }

        .footer {
            padding: var(--space-lg) var(--space-md);
            border-top: 1px solid var(--border);
        }

        .footer-inner {
            max-width: var(--content-width);
            margin: 0 auto;
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: var(--space-sm);
        }

        .footer-brand {
            font-family: var(--font-display);
            font-size: 0.9rem;
            font-weight: 600;
            color: var(--text);
        }

        /* ========================================
           RESPONSIVE
           ======================================== */

        @media (max-width: 600px) {
            html {
                font-size: 16px;
            }

            .header-inner,
            .footer-inner {
                flex-direction: column;
                align-items: flex-start;
                gap: var(--space-xs);
            }

            .hero {
                padding: var(--space-lg) var(--space-md) var(--space-xl);
            }

            .hero-title {
                font-size: 1.9rem;
            }

            .section {
                padding: var(--space-lg) 0;
            }

            .section-title {
                font-size: 1.35rem;
            }
        }
        /* Audio Player */
        .audio-player {
            display: flex;
            align-items: center;
            gap: var(--space-sm);
            background: var(--bg-alt);
            border: 1px solid var(--border);
            border-radius: 12px;
            padding: var(--space-sm) var(--space-md);
            margin-top: var(--space-md);
            max-width: 400px;
        }
        .audio-player svg { flex-shrink: 0; color: var(--accent); }
        .audio-player audio { flex: 1; height: 36px; min-width: 0; }
        .audio-player-label { font-family: var(--font-body); font-size: 0.85rem; color: var(--text-secondary); white-space: nowrap; }
    </style>
</head>
<body>
    <header class="header">
        <div class="header-inner">
            <a href="index.html" class="newsletter-brand">JLW Newsletter</a>
            <time class="newsletter-date">January 18, 2026</time>
        </div>
    </header>

    <section class="hero">
        <div class="hero-inner">
            <span class="hero-label">LLM Forecast</span>
            <h1 class="hero-title">The Next Three Years of LLM Performance</h1>
            <p class="hero-subtitle">Infrastructure bets measured in hundreds of billions. Benchmark scores approaching 100%. A new definition of "performance" emerging. Here's what the past week reveals about where AI is headed through 2028.</p>
            <div class="audio-player">
                <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 18V5l12-2v13"/><circle cx="6" cy="18" r="3"/><circle cx="18" cy="16" r="3"/></svg>
                <span class="audio-player-label">Listen</span>
                <audio controls preload="metadata">
                    <source src="audio/the-next-three-years-of-llm.wav" type="audio/wav">
                </audio>
            </div>

            <div class="hero-image">
                <img src="images/hero-llm-forecast-2026.jpg" alt="Abstract visualization of neural pathways converging toward a luminous horizon, representing AI capability trajectories">
            </div>
        </div>
    </section>

    <main class="content">
        <!-- SECTION 1: Stargate Expansion -->
        <article class="section">
            <span class="section-number">01</span>
            <h2 class="section-title">Half a Trillion Dollars Says the Scaling Thesis Isn't Dead</h2>
            <div class="section-meta">
                <span class="section-source">via <a href="https://amiko.consulting/">Amiko Consulting</a></span>
                <span class="section-date">January 16, 2026</span>
            </div>
            <figure class="article-image">
                <img src="images/article-01-stargate-datacenters.jpg" alt="Futuristic data centers rising across an industrial landscape with glowing server racks">
            </figure>
            <div class="section-body">
                <p>When <a href="https://openai.com">OpenAI</a>, <a href="https://oracle.com">Oracle</a>, and <a href="https://softbank.com">SoftBank</a> announced five new sites for the Stargate supercomputer project this week, the number that matters isn't five—it's $500 billion. That's the target investment for an initiative explicitly designed to build "the physical backbone for AGI-level systems."</p>

                <p>The timing is revealing. Just as armchair critics declared pre-training scaling dead, the people with the most to lose are doubling down on infrastructure at a scale that makes previous AI investments look like rounding errors. OpenAI is simultaneously issuing RFPs for domestic U.S. manufacturing of data center components—a supply chain play that suggests they're planning for hardware demands that don't exist yet.</p>

                <figure class="chart">
                    <img src="images/chart-infra-investment.png" alt="Bar chart comparing AI infrastructure investments: Stargate at $500B dwarfs all prior efforts">
                    <figcaption>The 2026 infrastructure bets aren't incremental—they're a different order of magnitude entirely.</figcaption>
                </figure>

                <p>The subtext is unmistakable: the constraint on 2027-2028 models isn't algorithms or data—it's power and physical space. If you believe scaling has hit diminishing returns, you have to explain why the labs building frontier models are acting like the opposite is true.</p>
            </div>
        </article>

        <!-- SECTION 2: Agentic AI -->
        <article class="section">
            <span class="section-number">02</span>
            <h2 class="section-title">The New Definition of "Performance": It's Not About Single Prompts Anymore</h2>
            <div class="section-meta">
                <span class="section-source">via <a href="https://artificialintelligence-newstoday.com/">AI News Today</a></span>
                <span class="section-date">January 16, 2026</span>
            </div>
            <figure class="article-image">
                <img src="images/article-02-agentic-cowork.jpg" alt="Abstract visualization of AI agents collaborating in a digital workspace with flowing data streams">
            </figure>
            <div class="section-body">
                <p>Here's a prediction you can hold me to: by 2028, the benchmarks we obsess over today will feel quaint. This week's industry analysis highlighted the shift to "self-verifying" agents—systems that monitor their own outputs, catch errors, and iterate across multi-step workflows without human intervention.</p>

                <p><a href="https://anthropic.com">Anthropic's</a> "Cowork" concept captures the trajectory: an "always-on workplace teammate" that doesn't wait for prompts but proactively handles document workflows. <a href="https://forrester.com">Forrester</a> forecasts this won't collapse jobs outright but will fundamentally alter white-collar roles—the difference between a calculator replacing arithmetic and spreadsheets replacing entire accounting departments.</p>

                <div class="callout">
                    <p><strong>The shift:</strong> "Performance" is evolving from single-prompt accuracy (MMLU, HumanEval) to reliability in long-horizon autonomous workflows. The models that matter in 2028 won't be the ones with the highest benchmark scores—they'll be the ones that can run for hours without human correction.</p>
                </div>

                <p>This redefines what "better" even means. A model that scores 95% on a reasoning benchmark but fails 10% of agentic tasks is less useful than one scoring 85% that succeeds 99% of the time on real-world workflows. The industry is just starting to grapple with how to measure this.</p>
            </div>
        </article>

        <!-- SECTION 3: Physical AI -->
        <article class="section">
            <span class="section-number">03</span>
            <h2 class="section-title">Beyond Text: The ChatGPT Moment for Robotics</h2>
            <div class="section-meta">
                <span class="section-source">via <a href="https://marketingprofs.com/">MarketingProfs</a></span>
                <span class="section-date">January 16, 2026</span>
            </div>
            <figure class="article-image">
                <img src="images/article-03-physical-ai.jpg" alt="Humanoid robot hand reaching toward a holographic interface, merging digital and physical realms">
            </figure>
            <div class="section-body">
                <p><a href="https://nvidia.com">Nvidia</a> CEO Jensen Huang declared this week that "the ChatGPT moment in robotics has arrived," announcing new open "Cosmos" models for physical AI. Meanwhile, Chinese lab <a href="https://deepseek.com">DeepSeek</a> is expected to launch V4 in February targeting coding dominance. The frontier is expanding in every direction.</p>

                <p>This matters for the 3-year forecast because "LLM performance" is no longer just about text. The same architectures powering chatbots are being adapted to control robots, process video in real-time, and coordinate multi-modal workflows. By 2028, asking "how good is GPT-7?" will require specifying whether you mean at math, coding, driving a car, or folding laundry.</p>

                <figure class="chart">
                    <img src="images/chart-capability-timeline.png" alt="Line chart showing LLM capability trajectories 2023-2028: reasoning and coding near saturation, agents and physical AI growing rapidly">
                    <figcaption>Reasoning and coding approach saturation while agentic and physical AI capabilities have the most room to run.</figcaption>
                </figure>

                <p>The capability curves tell the story. Reasoning and coding are approaching ceiling effects—there's not much room left to improve on AIME when you're already at 100%. But autonomous agents and physical AI have years of rapid improvement ahead. The research attention will follow the opportunity.</p>
            </div>
        </article>

        <!-- SECTION 4: Cerebras Deal -->
        <article class="section">
            <span class="section-number">04</span>
            <h2 class="section-title">$10 Billion to Break the Nvidia Dependency</h2>
            <div class="section-meta">
                <span class="section-source">via <a href="https://techstartups.com/">TechStartups</a></span>
                <span class="section-date">January 15, 2026</span>
            </div>
            <figure class="article-image">
                <img src="images/article-04-cerebras-wafer.jpg" alt="Massive wafer-scale computing chip glowing with internal circuits, macro photography style">
            </figure>
            <div class="section-body">
                <p><a href="https://openai.com">OpenAI</a> secured roughly 750 megawatts of compute capacity through a deal with <a href="https://cerebras.ai">Cerebras</a> valued over $10 billion. This isn't just another cloud contract—it's a strategic pivot from purely Azure-based training to owning industrial-scale hardware infrastructure.</p>

                <p>The goal is explicit: reduce dependence on <a href="https://nvidia.com">Nvidia</a> by diversifying into Cerebras' wafer-scale engines. These aren't GPUs—they're entire chips the size of dinner plates, optimized for the specific computation patterns of transformer training. If they work at scale, they could break the H100/H200 stranglehold that currently constrains training capacity.</p>

                <p>For the 3-year outlook, this signals that hardware architecture is becoming a competitive dimension again. The labs that find ways around the GPU bottleneck will have a structural advantage in training GPT-6 class models. The ones that don't will be waiting in line for Nvidia allocation like everyone else.</p>
            </div>
        </article>

        <!-- SECTION 5: Geopolitics -->
        <article class="section">
            <span class="section-number">05</span>
            <h2 class="section-title">The Splinternet of AI: Hardware Walls Go Up</h2>
            <div class="section-meta">
                <span class="section-source">via <a href="https://theguardian.com/">The Guardian</a></span>
                <span class="section-date">January 15, 2026</span>
            </div>
            <figure class="article-image">
                <img src="images/article-05-geopolitical-split.jpg" alt="Two diverging digital pathways across a globe with semiconductor chips floating between continents">
            </figure>
            <div class="section-body">
                <p>The U.S. implemented 25% tariffs on advanced GPUs destined for China this week, while China reportedly banned Nvidia H200 chips entirely. Add the EU's AI Omnibus and New York's AI Act, and you have the clearest picture yet of what LLM development looks like in a fractured regulatory landscape.</p>

                <p>The immediate effect is a decoupling of hardware ecosystems. Western and Chinese frontier models will evolve on completely different chip architectures, with different capabilities and constraints. This isn't theoretical—it's happening now, and it will shape what "state of the art" even means by 2028.</p>

                <p>For Western labs, the constraint is navigating export controls while maintaining training capacity. For Chinese labs, it's developing indigenous alternatives fast enough to stay competitive. Both sides are betting enormous sums that their approach will win. The next three years will settle the question.</p>
            </div>
        </article>

        <!-- SECTION 6: Gemini + Siri -->
        <article class="section">
            <span class="section-number">06</span>
            <h2 class="section-title">The Hybrid Architecture Goes Mainstream</h2>
            <div class="section-meta">
                <span class="section-source">via <a href="https://eweek.com/">eWeek</a></span>
                <span class="section-date">January 12, 2026</span>
            </div>
            <figure class="article-image">
                <img src="images/article-06-hybrid-ai.jpg" alt="Smartphone surrounded by ambient AI intelligence aura, blending on-device and cloud processing">
            </figure>
            <div class="section-body">
                <p><a href="https://apple.com">Apple</a> and <a href="https://google.com">Google</a> formalized a partnership this week to power next-generation Siri with <a href="https://deepmind.google/technologies/gemini/">Gemini</a>. The deal validates the "hybrid AI" approach: Apple retains control over on-device processing for simple queries and privacy-sensitive tasks, while complex reasoning offloads to Google's cloud.</p>

                <p>This matters because it cements Gemini as critical infrastructure for consumer devices—potentially reaching billions of users through iOS 26.4. The partnership also reveals what the major players believe about deployment: neither pure cloud nor pure edge wins. The future is intelligent routing between both.</p>

                <p>By 2028, expect every major device ecosystem to have similar hybrid architectures. The performance question becomes: how seamlessly can systems switch between local and cloud inference, and how do you benchmark something that depends on network latency as much as model quality?</p>
            </div>
        </article>

        <!-- SECTION 7: OpenAI Roadmap -->
        <article class="section">
            <span class="section-number">07</span>
            <h2 class="section-title">OpenAI's Multi-Tier Strategy: One Model No Longer Rules All</h2>
            <div class="section-meta">
                <span class="section-source">via <a href="https://i10x.ai/">i10x.ai</a></span>
                <span class="section-date">January 11, 2026</span>
            </div>
            <figure class="article-image">
                <img src="images/article-07-gpt5-tiers.jpg" alt="Three ascending tiers of AI capability visualized as layered geometric platforms glowing with increasing intensity">
            </figure>
            <div class="section-body">
                <p><a href="https://openai.com">OpenAI's</a> 2026 roadmap introduced a tiered model family that abandons the "one model for everything" approach. GPT-5 targets developers with coding and agent capabilities. GPT-5.2 is a premium "knowledge work" tier with extended context and advanced reasoning. And gpt-oss brings open-weight models for self-hosting.</p>

                <figure class="chart">
                    <img src="images/chart-gpt5-benchmarks.png" alt="Bar chart comparing GPT-5 and GPT-5.2 benchmark performance across AIME, SWE-bench, ARC-AGI-2, and MMLU Pro">
                    <figcaption>GPT-5.2 significantly outperforms GPT-5 on coding (SWE-bench) and reasoning (ARC-AGI-2) benchmarks—the premium tier isn't just marketing.</figcaption>
                </figure>

                <p>The numbers are striking: GPT-5 hits 100% on AIME 2026 (a math competition benchmark), while GPT-5.2 reaches 80% on SWE-bench Verified and 52.9% on ARC-AGI-2. These aren't incremental improvements—they're capability cliffs that separate tiers.</p>

                <p>The strategic implication is clear: by 2028, "what model are you using?" will be as meaningless as "what car do you drive?" without specifying the model and trim level. The frontier isn't one point—it's a product line with different price-performance tradeoffs for different use cases.</p>
            </div>
        </article>
    </main>

    <section class="closing">
        <div class="closing-inner">
            <h2 class="closing-title">What to Watch</h2>
            <p class="closing-text">The next three years will be defined by three races: infrastructure scale (who can build and power the most compute), architecture innovation (who breaks the GPU bottleneck first), and capability breadth (who extends from text to agents to physical AI fastest). The bets are placed. Now we watch them play out.</p>
        </div>
    </section>

    <footer class="footer">
        <div class="footer-inner">
            <span class="footer-brand">JLW Newsletter</span>
        </div>
    </footer>
</body>
</html>
